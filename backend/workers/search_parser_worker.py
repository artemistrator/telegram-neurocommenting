"""
Search Parser Worker

–í–æ—Ä–∫–µ—Ä –¥–ª—è –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ Telegram-–∫–∞–Ω–∞–ª–æ–≤ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º.
–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç MOCK —Ä–µ–∂–∏–º –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –±–µ–∑ Telegram –∞–∫–∫–∞—É–Ω—Ç–æ–≤.
"""

import asyncio
import logging
import os
import random
import sys
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Tuple

from telethon import TelegramClient
from telethon.sessions import StringSession
from telethon.tl.functions.contacts import SearchRequest
from telethon.tl.types import Channel
from telethon.errors import FloodWaitError

# Add parent directory to path
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from backend.directus_client import DirectusClient

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Configuration
MOCK_MODE = os.getenv('SEARCH_MOCK_MODE', 'true').lower() == 'true'
SEARCH_INTERVAL = int(os.getenv('SEARCH_INTERVAL', '3600'))
SEARCH_MIN_SUBSCRIBERS = int(os.getenv('SEARCH_MIN_SUBSCRIBERS', '1000'))
SEARCH_MAX_RESULTS = int(os.getenv('SEARCH_MAX_RESULTS', '50'))
SEARCH_REQUEST_DELAY_MIN = int(os.getenv('SEARCH_REQUEST_DELAY_MIN', '5'))
SEARCH_REQUEST_DELAY_MAX = int(os.getenv('SEARCH_REQUEST_DELAY_MAX', '10'))

# Initialize Directus client
directus = DirectusClient()

# Mock channel names for testing
MOCK_CHANNEL_NAMES = [
    "–ì—Ä—É–∑–æ–ø–µ—Ä–µ–≤–æ–∑–∫–∏ –†–§",
    "–õ–æ–≥–∏—Å—Ç–∏–∫–∞ –∏ –¥–æ—Å—Ç–∞–≤–∫–∞",
    "–ü–µ—Ä–µ–≤–æ–∑–∫–∏ –ø–æ –†–æ—Å—Å–∏–∏",
    "Cargo Russia",
    "–î–æ—Å—Ç–∞–≤–∫–∞ –≥—Ä—É–∑–æ–≤",
    "–¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç –∏ –ª–æ–≥–∏—Å—Ç–∏–∫–∞",
    "–ì—Ä—É–∑–æ–≤—ã–µ –ø–µ—Ä–µ–≤–æ–∑–∫–∏ 24/7",
    "–≠–∫—Å–ø—Ä–µ—Å—Å –¥–æ—Å—Ç–∞–≤–∫–∞",
    "–ú–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã–µ –ø–µ—Ä–µ–≤–æ–∑–∫–∏",
    "–õ–æ–≥–∏—Å—Ç–∏–∫–∞ –ú–æ—Å–∫–≤–∞",
    "–ì—Ä—É–∑–æ–≤–æ–π —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç",
    "–ü–µ—Ä–µ–≤–æ–∑–∫–∏ –∏ —Å–∫–ª–∞–¥–∏—Ä–æ–≤–∞–Ω–∏–µ",
    "–¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω–∞—è –∫–æ–º–ø–∞–Ω–∏—è",
    "–õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ä–µ—à–µ–Ω–∏—è",
    "–ì—Ä—É–∑–æ–ø–µ—Ä–µ–≤–æ–∑–∫–∏ –æ–Ω–ª–∞–π–Ω",
    "–î–æ—Å—Ç–∞–≤–∫–∞ –ø–æ –≤—Å–µ–π –†–æ—Å—Å–∏–∏",
    "–ö–∞—Ä–≥–æ —Å–µ—Ä–≤–∏—Å",
    "–õ–æ–≥–∏—Å—Ç–∏–∫–∞ –∏ —Å–∫–ª–∞–¥",
    "–¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω—ã–µ —É—Å–ª—É–≥–∏",
    "–ì—Ä—É–∑–æ–≤—ã–µ –∞–≤—Ç–æ–ø–µ—Ä–µ–≤–æ–∑–∫–∏"
]


async def should_search_now(keyword_data: Dict) -> bool:
    """
    –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω—É–∂–Ω–æ –ª–∏ –≤—ã–ø–æ–ª–Ω—è—Ç—å –ø–æ–∏—Å–∫ –¥–ª—è keyword.
    
    Args:
        keyword_data: –î–∞–Ω–Ω—ã–µ keyword –∏–∑ search_keywords
    
    Returns:
        True –µ—Å–ª–∏ –Ω—É–∂–Ω–æ –∏—Å–∫–∞—Ç—å, False –µ—Å–ª–∏ –Ω–µ—Ç
    """
    frequency = keyword_data.get('search_frequency', 'once')
    last_search_at = keyword_data.get('last_search_at')
    
    # –ï—Å–ª–∏ –µ—â—ë –Ω–µ –∏—Å–∫–∞–ª–∏ - –Ω—É–∂–Ω–æ –∏—Å–∫–∞—Ç—å
    if not last_search_at:
        return True
    
    # –ï—Å–ª–∏ frequency='once' –∏ —É–∂–µ –∏—Å–∫–∞–ª–∏ - –Ω–µ –Ω—É–∂–Ω–æ
    if frequency == 'once':
        return False
    
    # –ü–∞—Ä—Å–∏–º last_search_at
    try:
        if isinstance(last_search_at, str):
            last_search = datetime.fromisoformat(last_search_at.replace('Z', '+00:00'))
        else:
            last_search = last_search_at
    except Exception as e:
        logger.warning(f"[Search Parser] –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ last_search_at: {e}, —Å—á–∏—Ç–∞–µ–º —á—Ç–æ –Ω—É–∂–Ω–æ –∏—Å–∫–∞—Ç—å")
        return True
    
    now = datetime.now(last_search.tzinfo) if last_search.tzinfo else datetime.now()
    time_passed = now - last_search
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ —á–∞—Å—Ç–æ—Ç–µ
    if frequency == 'hourly':
        return time_passed >= timedelta(hours=1)
    elif frequency == 'daily':
        return time_passed >= timedelta(days=1)
    elif frequency == 'weekly':
        return time_passed >= timedelta(weeks=1)
    
    # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –Ω–µ –∏—Å–∫–∞—Ç—å
    return False


async def generate_mock_channels(keyword: str, count: int = None) -> List[Dict]:
    """
    –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ñ–µ–π–∫–æ–≤—ã—Ö –∫–∞–Ω–∞–ª–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è.
    
    Args:
        keyword: –ö–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ –¥–ª—è –ø–æ–∏—Å–∫–∞
        count: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–Ω–∞–ª–æ–≤ (–µ—Å–ª–∏ None - —Å–ª—É—á–∞–π–Ω–æ–µ 3-5)
    
    Returns:
        –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –¥–∞–Ω–Ω—ã–º–∏ –∫–∞–Ω–∞–ª–æ–≤
    """
    if count is None:
        count = random.randint(3, 5)
    
    channels = []
    used_names = set()
    
    for _ in range(count):
        # –í—ã–±–∏—Ä–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ
        while True:
            channel_name = random.choice(MOCK_CHANNEL_NAMES)
            if channel_name not in used_names:
                used_names.add(channel_name)
                break
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º username
        base_username = channel_name.lower().replace(' ', '_')
        channel_username = f"{base_username}_{random.randint(1, 999)}"
        
        # –°–ª—É—á–∞–π–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        subscribers_count = random.randint(500, 25000)
        has_comments = random.choice([True, False])
        posts_with_comments = random.randint(5, 15) if has_comments else 0
        
        channel_data = {
            'channel_title': channel_name,
            'channel_username': channel_username,
            'channel_url': f"https://t.me/{channel_username}",
            'subscribers_count': subscribers_count,
            'has_comments_enabled': has_comments,
            'last_post_id': random.randint(1000, 9999) if has_comments else None,
            'posts_with_comments': posts_with_comments
        }
        
        channels.append(channel_data)
    
    logger.info(f"[MOCK] –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {count} —Ñ–µ–π–∫–æ–≤—ã—Ö –∫–∞–Ω–∞–ª–æ–≤")
    return channels


async def get_search_account() -> Optional[Dict]:
    """
    –ù–∞–π—Ç–∏ –ø–æ–¥—Ö–æ–¥—è—â–∏–π –∞–∫–∫–∞—É–Ω—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞.
    –ö—Ä–∏—Ç–µ—Ä–∏–∏: active, work_mode IN [listener, commenter].
    Prefer listener (sort -work_mode).
    
    Returns:
        –î–∞–Ω–Ω—ã–µ –∞–∫–∫–∞—É–Ω—Ç–∞ –∏–ª–∏ None
    """
    try:
        params = {
            "filter[status][_eq]": "active",
            "filter[work_mode][_in]": "listener,commenter",
            "filter[proxy_unavailable][_neq]": "true",
            "fields": "id,phone,session_string,api_id,api_hash,proxy_unavailable,proxy_id.id,proxy_id.host,proxy_id.port,proxy_id.type,proxy_id.username,proxy_id.password,proxy_id.status,proxy_id.assigned_to",
            "sort": "-work_mode",
            "limit": 1
        }
        
        response = await directus.safe_get("/items/accounts", params=params)
        data = response.json().get('data', [])
        
        if data:
            return data[0]
        
        logger.warning("[Search Parser] –ù–µ –Ω–∞–π–¥–µ–Ω–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö –∞–∫–∫–∞—É–Ω—Ç–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞")
        return None
        
    except Exception as e:
        logger.error(f"[Search Parser] –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –∞–∫–∫–∞—É–Ω—Ç–∞: {e}")
        return None


async def search_telegram_real(keyword: str, min_subscribers: int) -> List[Dict]:
    """
    –†–µ–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ –≤ Telegram —á–µ—Ä–µ–∑ Telethon.
    
    Args:
        keyword: –ö–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ –¥–ª—è –ø–æ–∏—Å–∫–∞
        min_subscribers: –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–¥–ø–∏—Å—á–∏–∫–æ–≤
    
    Returns:
        –°–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –∫–∞–Ω–∞–ª–æ–≤
    """
    account = await get_search_account()
    if not account:
        return []

    if account.get('proxy_unavailable'):
        logger.warning(f"[Search Parser] SKIP account {account.get('phone')}: Proxy unavailable")
        return []

    logger.info(f"[Search Parser] –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞–∫–∫–∞—É–Ω—Ç {account.get('phone')} –¥–ª—è –ø–æ–∏—Å–∫–∞ '{keyword}'")

    try:
        # Create client via factory (with mandatory proxy)
        try:
            from backend.services.telegram_client_factory import get_client_for_account, format_proxy
            
            client = await get_client_for_account(account, directus)
            
            # Safe logging before connect (no credentials)
            proxy = account.get('proxy_id')
            if proxy:
                logger.info(f"[TG] connect account_id={account['id']} phone={account['phone']} via {format_proxy(proxy)}")
            else:
                logger.info(f"[TG] connect account_id={account['id']} phone={account['phone']} - no proxy info")
                
        except (ValueError, RuntimeError) as e:
            # Factory error: missing proxy, invalid proxy status, etc.
            logger.error(f"[Search Parser] Cannot create Telegram client for account {account['id']}: {e}")
            logger.info("[Search Parser] Skipping search due to proxy error")
            return []
        
        await client.connect()
        
        if not await client.is_user_authorized():
            logger.error(f"[Search Parser] –ê–∫–∫–∞—É–Ω—Ç {account.get('phone')} –Ω–µ –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω!")
            await client.disconnect()
            return []

        found_channels = []
        
        try:
            # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫
            result = await client(SearchRequest(
                q=keyword,
                limit=SEARCH_MAX_RESULTS
            ))
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            # SearchRequest –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç contacts.Found, –∫–æ—Ç–æ—Ä—ã–π —Å–æ–¥–µ—Ä–∂–∏—Ç lists: results, chats, users
            for chat in result.chats:
                try:
                    # –ù–∞—Å –∏–Ω—Ç–µ—Ä–µ—Å—É—é—Ç —Ç–æ–ª—å–∫–æ –∫–∞–Ω–∞–ª—ã (–∏ —Å—É–ø–µ—Ä–≥—Ä—É–ø–ø—ã)
                    if not isinstance(chat, Channel):
                        continue
                    
                    # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∫–∞–Ω–∞–ª—ã –±–µ–∑ —é–∑–µ—Ä–Ω–µ–π–º–∞ (–Ω–µ –º–æ–∂–µ–º —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å —Å—Å—ã–ª–∫—É)
                    if not chat.username:
                        continue
                        
                    # –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–¥–ø–∏—Å—á–∏–∫–æ–≤ (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ)
                    subscribers_count = getattr(chat, 'participants_count', 0)
                    if subscribers_count is None:
                        subscribers_count = 0
                        
                    # –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ
                    channel_data = {
                        'channel_title': chat.title,
                        'channel_username': chat.username,
                        'channel_url': f"https://t.me/{chat.username}",
                        'subscribers_count': subscribers_count,
                        'has_comments_enabled': True,  # –°—á–∏—Ç–∞–µ–º True –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é, –∫–∞–∫ –ø—Ä–æ—Å–∏–ª–∏
                        'last_post_id': None,  # –ú–æ–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å —á–µ—Ä–µ–∑ GetHistoryRequest, –Ω–æ —ç—Ç–æ –¥–æ–ø. –∑–∞–ø—Ä–æ—Å
                        'posts_with_comments': 0  # Placeholder
                    }
                    
                    found_channels.append(channel_data)
                    
                except Exception as e:
                    logger.error(f"[Search Parser] –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —á–∞—Ç–∞ {chat.id}: {e}")
                    continue

        except FloodWaitError as e:
            logger.warning(f"[Search Parser] FloodWaitError: –∂–¥–∏—Ç–µ {e.seconds} —Å–µ–∫")
            # –ú–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å sleep, –Ω–æ –ª—É—á—à–µ —Å–∫–∏–ø–Ω—É—Ç—å —ç—Ç–æ—Ç —Ü–∏–∫–ª
        except Exception as e:
            logger.error(f"[Search Parser] –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ SearchRequest: {e}")
            
        finally:
            await client.disconnect()
            
        return found_channels

    except Exception as e:
        logger.error(f"[Search Parser] –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ Telethon: {e}")
        return []


async def search_telegram(keyword: str, min_subscribers: int) -> List[Dict]:
    """
    –ü–æ–∏—Å–∫ –≤ Telegram (—Ä–µ–∞–ª—å–Ω—ã–π –∏–ª–∏ mock).
    
    Args:
        keyword: –ö–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ –¥–ª—è –ø–æ–∏—Å–∫–∞
        min_subscribers: –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–¥–ø–∏—Å—á–∏–∫–æ–≤
    
    Returns:
        –°–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –∫–∞–Ω–∞–ª–æ–≤
    """
    if MOCK_MODE:
        # Mock —Ä–µ–∂–∏–º
        await asyncio.sleep(random.uniform(1, 2))  # –ò–º–∏—Ç–∞—Ü–∏—è –∑–∞–¥–µ—Ä–∂–∫–∏
        return await generate_mock_channels(keyword)
    else:
        # –†–µ–∞–ª—å–Ω—ã–π —Ä–µ–∂–∏–º
        return await search_telegram_real(keyword, min_subscribers)


async def calculate_priority(subscribers: int, posts_with_comments: int) -> int:
    """
    –†–∞—Å—á—ë—Ç –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞ –∫–∞–Ω–∞–ª–∞.
    
    –§–æ—Ä–º—É–ª–∞: (subscribers_count / 1000) + (posts_with_comments * 2)
    –î–∏–∞–ø–∞–∑–æ–Ω: 1-10
    
    Args:
        subscribers: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–¥–ø–∏—Å—á–∏–∫–æ–≤
        posts_with_comments: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Å—Ç–æ–≤ —Å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è–º–∏
    
    Returns:
        –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç –æ—Ç 1 –¥–æ 10
    """
    priority = int((subscribers / 1000) + (posts_with_comments * 2))
    return min(10, max(1, priority))


async def channel_exists(channel_url: str) -> bool:
    """
    –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ –∫–∞–Ω–∞–ª –≤ found_channels.
    
    Args:
        channel_url: URL –∫–∞–Ω–∞–ª–∞
    
    Returns:
        True –µ—Å–ª–∏ –∫–∞–Ω–∞–ª —É–∂–µ –µ—Å—Ç—å –≤ –ë–î
    """
    try:
        params = {
            "filter[channel_url][_eq]": channel_url,
            "limit": 1,
            "fields": "id"
        }
        
        response = await directus.safe_get("/items/found_channels", params=params)
        data = response.json().get('data', [])
        
        return len(data) > 0
        
    except Exception as e:
        logger.error(f"[Search Parser] –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥—É–±–ª–∏–∫–∞—Ç–∞: {e}")
        return False


async def save_found_channel(keyword_id: int, channel_data: Dict, user_created: Optional[str] = None) -> bool:
    """
    –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –Ω–∞–π–¥–µ–Ω–Ω—ã–π –∫–∞–Ω–∞–ª –≤ found_channels.
    
    Args:
        keyword_id: ID keyword –∏–∑ search_keywords
        channel_data: –î–∞–Ω–Ω—ã–µ –∫–∞–Ω–∞–ª–∞
        user_created: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Å–æ–∑–¥–∞–≤—à–µ–≥–æ keyword
    
    Returns:
        True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ
    """
    try:
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–∞
        channel_url = channel_data['channel_url']
        if await channel_exists(channel_url):
            logger.info(f"[Search Parser] ‚äò –ö–∞–Ω–∞–ª {channel_url} —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, —Å–∫–∏–ø")
            return False
        
        # –†–∞—Å—á—ë—Ç –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞
        priority = await calculate_priority(
            channel_data['subscribers_count'],
            channel_data['posts_with_comments']
        )
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        save_data = {
            'search_keyword_id': keyword_id,
            'channel_url': channel_data['channel_url'],
            'channel_username': channel_data['channel_username'],
            'channel_title': channel_data['channel_title'],
            'subscribers_count': channel_data['subscribers_count'],
            'has_comments_enabled': channel_data['has_comments_enabled'],
            'last_post_id': channel_data.get('last_post_id'),
            'posts_with_comments': channel_data['posts_with_comments'],
            'status': 'pending',
            'subscription_priority': priority
        }
        
        if user_created:
            save_data['user_created'] = user_created
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
        await directus.create_item('found_channels', save_data)
        
        logger.info(
            f"[Search Parser] ‚úì –°–æ—Ö—Ä–∞–Ω—ë–Ω –∫–∞–Ω–∞–ª: {channel_data['channel_title']} "
            f"(–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç: {priority})"
        )
        return True
        
    except Exception as e:
        logger.error(f"[Search Parser] ERROR: –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–∞–Ω–∞–ª–∞: {e}")
        return False


async def process_keyword(keyword_data: Dict) -> None:
    """
    –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ keyword: –ø–æ–∏—Å–∫, —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è, —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ.
    
    Args:
        keyword_data: –î–∞–Ω–Ω—ã–µ keyword –∏–∑ search_keywords
    """
    keyword_id = keyword_data['id']
    keyword_text = keyword_data['keyword']
    min_subscribers = keyword_data.get('min_subscribers', SEARCH_MIN_SUBSCRIBERS)
    user_created = keyword_data.get('user_created')
    
    prefix = "[MOCK]" if MOCK_MODE else "[Search Parser]"
    logger.info(f"{prefix} Keyword '{keyword_text}' - –Ω–∞—á–∏–Ω–∞–µ–º –ø–æ–∏—Å–∫")
    
    try:
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω—É–∂–Ω–æ –ª–∏ –∏—Å–∫–∞—Ç—å
        if not await should_search_now(keyword_data):
            logger.info(f"{prefix} Keyword '{keyword_text}' - –ø–æ–∏—Å–∫ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è (–ø–æ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—é)")
            return
        
        # –ü–æ–∏—Å–∫ –∫–∞–Ω–∞–ª–æ–≤
        channels = await search_telegram(keyword_text, min_subscribers)
        
        if not channels:
            logger.info(f"{prefix} Keyword '{keyword_text}' - –∫–∞–Ω–∞–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            # –û–±–Ω–æ–≤–ª—è–µ–º last_search_at –¥–∞–∂–µ –µ—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞—à–ª–∏
            await directus.update_item('search_keywords', keyword_id, {
                'last_search_at': datetime.now().isoformat()
            })
            return
        
        logger.info(f"{prefix} –ù–∞–π–¥–µ–Ω–æ {len(channels)} –∫–∞–Ω–∞–ª–æ–≤ –¥–ª—è '{keyword_text}'")
        
        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
        saved_count = 0
        skipped_count = 0
        
        for channel in channels:
            # –§–∏–ª—å—Ç—Ä –ø–æ –ø–æ–¥–ø–∏—Å—á–∏–∫–∞–º
            if channel['subscribers_count'] < min_subscribers:
                logger.info(
                    f"{prefix} ‚úó –°–∫–∏–ø: @{channel['channel_username']} - "
                    f"–º–∞–ª–æ –ø–æ–¥–ø–∏—Å—á–∏–∫–æ–≤ ({channel['subscribers_count']} < {min_subscribers})"
                )
                skipped_count += 1
                continue
            
            # –§–∏–ª—å—Ç—Ä –ø–æ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è–º
            if not channel['has_comments_enabled']:
                logger.info(
                    f"{prefix} ‚úó –°–∫–∏–ø: @{channel['channel_username']} - –∫–∞–Ω–∞–ª –±–µ–∑ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤"
                )
                skipped_count += 1
                continue
            
            # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞–Ω–∞–ª–∞
            logger.info(
                f"{prefix} –ö–∞–Ω–∞–ª @{channel['channel_username']} - "
                f"{channel['subscribers_count']} –ø–æ–¥–ø–∏—Å—á–∏–∫–æ–≤, –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏: –î–ê"
            )
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
            if await save_found_channel(keyword_id, channel, user_created):
                saved_count += 1
            else:
                skipped_count += 1
            
            # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è–º–∏
            if not MOCK_MODE:
                await asyncio.sleep(random.uniform(
                    SEARCH_REQUEST_DELAY_MIN,
                    SEARCH_REQUEST_DELAY_MAX
                ))
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ keyword
        await directus.update_item('search_keywords', keyword_id, {
            'last_search_at': datetime.now().isoformat(),
            'channels_found': saved_count
        })
        
        logger.info(
            f"{prefix} Keyword '{keyword_text}' –∑–∞–≤–µ—Ä—à—ë–Ω: "
            f"{saved_count}/{len(channels)} –∫–∞–Ω–∞–ª–æ–≤ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ"
        )
        
    except Exception as e:
        logger.error(f"{prefix} ERROR: –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ keyword '{keyword_text}': {e}")
        import traceback
        traceback.print_exc()


async def get_active_keywords() -> List[Dict]:
    """
    –ü–æ–ª—É—á–∏—Ç—å –∞–∫—Ç–∏–≤–Ω—ã–µ keywords –∏–∑ search_keywords.
    
    Returns:
        –°–ø–∏—Å–æ–∫ –∞–∫—Ç–∏–≤–Ω—ã—Ö keywords
    """
    try:
        params = {
            "filter[status][_eq]": "active",
            "fields": "id,keyword,search_frequency,last_search_at,min_subscribers,user_created",
            "limit": -1
        }
        
        response = await directus.safe_get("/items/search_keywords", params=params)
        keywords = response.json().get('data', [])
        
        logger.info(f"[Search Parser] –ù–∞–π–¥–µ–Ω–æ {len(keywords)} –∞–∫—Ç–∏–≤–Ω—ã—Ö keywords")
        return keywords
        
    except Exception as e:
        logger.error(f"[Search Parser] ERROR: –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è keywords: {e}")
        return []


async def search_cycle():
    """
    –û–¥–∏–Ω —Ü–∏–∫–ª –ø–æ–∏—Å–∫–∞: –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ—Ö –∞–∫—Ç–∏–≤–Ω—ã—Ö keywords.
    """
    logger.info("[Search Parser] –¶–∏–∫–ª –ø–æ–∏—Å–∫–∞ –∑–∞–ø—É—â–µ–Ω")
    
    try:
        # –ü–æ–ª—É—á–∏—Ç—å –∞–∫—Ç–∏–≤–Ω—ã–µ keywords
        keywords = await get_active_keywords()
        
        if not keywords:
            logger.info("[Search Parser] –ù–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã—Ö keywords –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
            return
        
        # –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –∫–∞–∂–¥—ã–π keyword
        for keyword_data in keywords:
            await process_keyword(keyword_data)
            
            # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É keywords
            await asyncio.sleep(2)
        
        logger.info("[Search Parser] ‚úì –¶–∏–∫–ª –ø–æ–∏—Å–∫–∞ –∑–∞–≤–µ—Ä—à—ë–Ω")
        
    except Exception as e:
        logger.error(f"[Search Parser] ERROR: –û—à–∏–±–∫–∞ –≤ —Ü–∏–∫–ª–µ –ø–æ–∏—Å–∫–∞: {e}")
        import traceback
        traceback.print_exc()


async def main():
    """
    –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –≤–æ—Ä–∫–µ—Ä–∞.
    """
    mode = "MOCK" if MOCK_MODE else "REAL"
    logger.info(f"üöÄ [Search Parser] Worker –∑–∞–ø—É—â–µ–Ω, —Ä–µ–∂–∏–º: {mode}")
    logger.info(f"   –ò–Ω—Ç–µ—Ä–≤–∞–ª: {SEARCH_INTERVAL}s")
    logger.info(f"   –ú–∏–Ω. –ø–æ–¥–ø–∏—Å—á–∏–∫–æ–≤: {SEARCH_MIN_SUBSCRIBERS}")
    logger.info(f"   –ú–∞–∫—Å. —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {SEARCH_MAX_RESULTS}")
    
    # Login to Directus
    try:
        await directus.login()
        logger.info("‚úì –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Directus")
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Directus: {e}")
        return
    
    # Main loop
    while True:
        try:
            await search_cycle()
        except Exception as e:
            logger.error(f"‚ùå –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –≤ –≥–ª–∞–≤–Ω–æ–º —Ü–∏–∫–ª–µ: {e}")
            import traceback
            traceback.print_exc()
        
        logger.info(f"üí§ –°–æ–Ω {SEARCH_INTERVAL}s –¥–æ —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ü–∏–∫–ª–∞...")
        await asyncio.sleep(SEARCH_INTERVAL)


if __name__ == "__main__":
    asyncio.run(main())
